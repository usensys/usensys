---
title: "USENSYS - Electric Power Sector"
author: "https://github.com/olugovoy/usensys"
output:
  pdf_document: 
    toc: yes
    toc_depth: 5
  html_document:
    toc: yes
    toc_depth: 5
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#knitr::opts_chunk$set(fig_width = 8, fig_height = 6)
source("install_packages.R")
library(energyRt)
library(lubridate)
library(tibble)
library(tidyverse)
# mySolver <- "GLPK" # not capable enough for large models
mySolver <- "GAMS" # default LP solver will be used (CPLEX is recommended)

if (!dir.exists("fig")) dir.create("fig")
if (!dir.exists("tmp")) dir.create("tmp")
if (!dir.exists("scenarios")) dir.create("scenarios")

```

# Overview  
  
This is the first draft of electric power sector, the renewables balancing version. The output of the optimization is capacity of renewables, storages, and interregional UHVDC grid with inverter and rectifier station capacity.  
The main purpose of this stage is testing functionality of the framework, and sketching further steps of the model development.  

**The current features of the model:**  
* 49 regions (48 lower states and Disctict of Columbia);  
* 1 year, 8760 hours (24x365);  
* actual demand of electricity in 2017 (monthly date by states, desagregated by hours using national load curve - will be improved on further steps);  
* Main technologies:
- solar and wind power farms,  
- electricity storage (hourly),  
- endogenous interregional grid (UHV lines and coverter stations),  
* MERRA-2 weather data (see bellow the aggregation procedure);  

**Technologies and features in progress (to be added on the next steps):**  
- static demand with fixed location,  
- static demand with optimized location,  
- demand-side management techs with fixed location,  
- demand-side management techs with optimized location
- ...

The model have been solved with GAMS/CPLEX. 
Time: >= 3 hours on 6-core, 5GHz Intel processor.    
The main hardware requirements is RAM >= 64Gb. 

The results of the optimization are saved in `` files.  


# Map data  
GIS information will be used for graphical output and calibration of some parameters (such as estimation of distances between regions for required electric power grid).
Map objects:
**usa49reg** - lower 48 states + DC, spatial polygon data frame;  
**usa49r** - lower 48 states + DC, data frame format.  

```{r Regions}
if (!file.exists("data/maps/usa49reg.RData")) {
  stop("US map data is not found. Follow the steps in 'usa_maps.R'")
} else {
  load("data/maps/usa49reg.RData")
}

ggplot(usa49r, aes(long,lat, group = group, fill = id)) + 
  geom_polygon(aes(fill = id), colour = rgb(1,1,1,.2)) +
  # geom_polygon(aes(fill = id), colour = "white", size = .75) +
  labs(fill = "Region") +
  coord_fixed(1.45) +
  # scale_fill_brewer(palette = "Paired") +
  #coord_quickmap() +
  theme_void() +
  theme(legend.position="none")
b <- last_plot()
# b + scale_fill_discrete()

(reg_names <- unique(as.character(usa49reg@data$region)))
(reg_names_in_gis <- as.character(usa49reg@data$region))

(nreg <- length(reg_names))
(nreg_in_gis <- length(usa49reg@data$region))

# Neighbor regions
nbr <- spdep::poly2nb(usa49reg)
names(nbr) <- usa49reg@data$region

# Centers of the regions
reg_centers <- get_labpt_spdf(usa49reg)


```


# Sub-annual time resolution (time-slices)  
  
Here we define two levels of time-slices:  
- the day of the year (*YDAY*), from 1 to 365;  
- the hour (1 to 24).  
Therefore we have 8760 time slices, named according to the format *"dNNN_hNN"*, where *N* - numbers.  

For convenience, let's define finctions to convert data-time into slices names and back.  

```{r Time_slices}
# A list with two levels slices
timeslices365 <- list(
  YDAY = paste0("d", formatC(1:365, width = 3, flag = "0")),
  HOUR = paste0("h", formatC(0:23, width = 2, flag = "0"))
)

# Function to convert data-time object into names of time-slices.
datetime2tsdh <- function(dt) {
  paste0("d", formatC(yday(dt), width = 3, flag = "0"), "_",
         "h", formatC(hour(dt), width = 2, flag = "0"))
}
# check
datetime2tsdh(today("EST"))

# Function to coerse time-slices names into data-time format, for a given year and time-zone.
tsdh2datetime <- function(tslice, year = 2017, tz = "EST") {
  DAY <- as.integer(substr(tslice, 2, 4)) - 1
  HOUR <- as.integer(substr(tslice, 7, 8))
  lubridate::ymd_h(paste0(year, "-01-01 0"), tz = tz) + days(DAY) + hours(HOUR)
}
# check
tsdh2datetime("d365_h23")

# data.frame object with names of the final time-slices in the model
#   and releted data-time information
slc365 <- tibble(
  slice = kronecker(timeslices365$YDAY, timeslices365$HOUR, FUN = "paste", sep = "_")
)
# add date-time info
slc365$syday <- substr(slc365$slice, 1, 4)
slc365$shour <- substr(slc365$slice, 6, 8)
slc365$yday <- as.integer(substr(slc365$slice, 2, 4))
slc365$hour <- as.integer(substr(slc365$slice, 7, 8))
slc365$datetime <- tsdh2datetime(slc365$slice)
slc365$month <- month(slc365$datetime)
slc365$week <- week(slc365$datetime)
head(slc365)
tail(slc365)


```


## Commodities

```{r Commodities}
ELC <- newCommodity('ELC', slice = "HOUR")
SOL <- newCommodity('SOL', slice = "HOUR")
WIN <- newCommodity('WIN', slice = "HOUR")
WFF <- newCommodity('WFF', slice = "HOUR")

UHV <- newCommodity(
  name = 'UHV', 
  description = "Ultra High Voltage electricity",
  slice = "HOUR")


```

## Demand  

Hourly demand by states with aggregated load curve (has to be updated with actual data)  

```{r ELC_demand}
eiadir <- file.path(getwd(), "data/EIA")
load(file.path(eiadir, "eia_raw.RData"))

# load curve data from:
# https://www.eia.gov/opendata/qb.php?sdid=EBA.US48-ALL.D.H
# Demand for United States Lower 48 (region), hourly - UTC time
lc <- read_csv("data/EIA/Demand_for_United_States_Lower_48_(region)_Hourly.csv", 
               skip = 5, col_names = c("datetime", "MWh"))
dim(lc)
head(lc)
lc$datetime_EST <- mdy_h(lc$datetime, tz = "EST")
lc$year <- year(lc$datetime_EST)
lc <- lc[lc$year == 2017, ]
lc$slice <- datetime2tsdh(lc$datetime_EST)
lc <- lc[order(lc$datetime),]
lc$month <- month(lc$datetime_EST)
lc$hGWh <- lc$MWh/1e3

# Check
dim(lc)
lc
sum(lc$MWh) / 1e6
summary(lc$hGWh)

mlc <- group_by(lc, month) %>%
  summarise(mGWh = sum(MWh)/1e3)
loadcurve <- full_join(select(lc, datetime_EST, slice, hGWh, month), mlc)
loadcurve$mshare <- loadcurve$hGWh / loadcurve$mGWh

# Check
group_by(loadcurve, month) %>%
  summarise(msum = sum(mshare))

elc_gen_2017 <- elc_gen[elc_gen$YEAR == 2017 & 
                          elc_gen$`TYPE OF PRODUCER` == "Total Electric Power Industry" &
                          elc_gen$`ENERGY SOURCE` == "Total" & 
                          elc_gen$STATE != "US-Total" &
                          elc_gen$STATE != "AK" & 
                          elc_gen$STATE != "HI",]
elc_gen_2017
sum(elc_gen_2017$`GENERATION\r\n(Megawatthours)`) / 1e6
sum(lc$MWh) / 1e6

length(unique(elc_gen_2017$STATE))

elc_gen_2017$GWh <- elc_gen_2017$`GENERATION\r\n(Megawatthours)`/1e3
elc_gen_2017$month <- as.integer(elc_gen_2017$MONTH)
elc_gen_2017$region <- elc_gen_2017$STATE
elc_gen_2017 <- select(elc_gen_2017, month, region, GWh)

elc_gen_mhr <- full_join(loadcurve, elc_gen_2017)
dim(elc_gen_mhr)[1]/49/365/24 == 1 # Check
elc_gen_mhr$GWh <- elc_gen_mhr$GWh * elc_gen_mhr$mshare
sum(elc_gen_mhr$GWh); sum(lc$hGWh); sum(elc_gen_2017$GWh)
# dim(elc_gen_mhr)
loadcurve <- select(elc_gen_mhr, -mGWh, -hGWh)
summary(loadcurve$GWh)

# Demand class
DEM_ELC_DH <- newDemand(
  name = "DEM_ELC_DH",
  commodity = "ELC",
  dem = data.frame(
    year = 2017, 
    region = c(
      loadcurve$region),
    slice = c(
      loadcurve$slice), 
    dem = round(loadcurve$GWh, 7)
    )
  # slice = "HOUR"
)

# Check
dim(DEM_ELC_DH@dem)
dim(DEM_ELC_DH@dem)[1] / 365 / 24
summary(DEM_ELC_DH@dem$dem)

# Demand data for mapping
elc_gen_map <- elc_gen_2017 %>%
  group_by(region) %>%
  summarise(TWh = sum(GWh)/1e3) %>%
  full_join(usa49r, by = c("region" = "id"))
elc_gen_map

ggplot(elc_gen_map) + 
  geom_polygon(aes(x = long, y = lat, group = group, fill = TWh), # fill = "wheat", 
               colour = "white", alpha = 1, size = .5) +
  scale_fill_distiller(palette = "Spectral") +
  coord_fixed(1.45) +
  theme_void()

ggsave("fig/elc_gen_map.png")  

  

```



# Weather factors  

Hourly weather information is used to estimate output of intermittent renewables, solar PVs and wind tourbines. The weather information is supplied as multipliers to availability factors of the generating technologies. I.e. availability of solar energy can be estimated based on solar radiation (flux) data, or actual output of the technology (PV) expected under complex weather data (direct and indirect solar irradience, temperature, and/or clouds etc.). The estimation can be done on grid data, then aggregated using potentially perspective and available locations for the installation of the sollar arrays. Here, for simplicity, we estimate availability of the solar resource based on NASA's *"surface net downward shortwave flux" (SWGNT, Watts per square meter)*, assuming that the full capacity of PV arrays is achieved at 800 W/m2 level of the flux. This estimate is certainly not the best one, can be improved.  
The estimated factors are aggregated for all availabel locations by states (which implies that allocation of PVs capacity is assumed to be evenly distributed across all the therritory in each state).  

For wind energy, wind-power curves are used to estimate potential output of wind-mills across locations with the best potential of wind energy.  

## Solar availability factors  

```{r Solar_potential_NASA}
# MERRA-2 data:
# https://gmao.gsfc.nasa.gov/reanalysis/MERRA-2/data_access/
# here we use data for one year only
load("data/MERRA2/nasa_sol_US49.RData")
gsol
summary(gsol$SWGNT)
hist(gsol$SWGNT[gsol$SWGNT > 0], col = "lightblue", probability = T,
     main = "SWGNT: Surface net downward shortwave flux, Watts/sq.m")

# Annual aggregate, kWh/day
ysol <- group_by(gsol, loc_id, lat, lon, region) %>%
  summarise(SWGNT = sum(SWGNT)/365/1e3)

ggplot(usa49r, aes(long, lat, group = group)) + 
  geom_polygon(colour = "black", fill = "wheat", alpha = .5) +
  coord_fixed(1.45) +
  theme_void() +
  geom_raster(data = ysol, aes(lon, lat, fill = SWGNT), interpolate = F, inherit.aes = F, alpha = .95) +
  scale_fill_distiller(palette = "YlOrRd", direction = 1)

# By months, kWh/day
msol <- group_by(gsol, loc_id, lat, lon, region, month) %>%
  summarise(SWGNT = sum(SWGNT/mdays)/1e3)

ggplot(usa49r, aes(long, lat, group = group)) + 
  geom_polygon(colour = "black", fill = "wheat", alpha = .5) +
  coord_fixed(1.45) +
  theme_void() +
  geom_raster(data = msol, aes(lon, lat, fill = SWGNT), interpolate = F, inherit.aes = F, alpha = .95) +
  scale_fill_distiller(palette = "YlOrRd", direction = 1) +
  facet_wrap(.~month)

# Aggregation regions
dhsol <- group_by(gsol, region, yday, hour) %>% # lat, lon, 
  summarise(SWGNT = mean(SWGNT))
summary(dhsol$SWGNT)

# Estimated weather factors
dhsol$WF <- dhsol$SWGNT / 800
dhsol$WF[dhsol$WF > 1] <- 1
dhsol$WF[dhsol$WF < .03] <- 0 # kick-starting irradiance
summary(dhsol$WF)
dhsol

# Add slice-names
dhsol$slice <- paste0("d", formatC(dhsol$yday, width = 3, flag = "0"), 
                      "_h", formatC(dhsol$hour, width = 2, flag = "0"))
dhsol
dim(dhsol)[1] / 365/24 # 48, i.e. one region is missing - DC

dhsol$region <- as.character(dhsol$region)
reg_names[!(reg_names %in% unique(dhsol$region))]

# Use MD weather data for DC
dhsol_DC <- dhsol[dhsol$region == "MD",]
dim(dhsol_DC)
dhsol_DC$region <- "DC"
dhsol_DC

# Add DC
dhsol <- bind_rows(dhsol, dhsol_DC)
dim(dhsol)[1] / 365/24
length(unique(dhsol$region)) == nreg # double-check

size(gsol); rm(gsol)

```

## Wind availability factors  

```{r Wind_potential_NASA}

# Hourly wind speed data at 50 meters height for US, 2017 
# (source: NASA/MERRA2, preprocessed)
load("data/merra2/nasa_wnd_US49.RData")
gwnd
if (is.factor(gwnd$region)) gwnd$region <- as.character(gwnd$region)

# Simplified aggregated wind-power curve as a function of wind speed.
# (assumed, should be replaced by read)
WindPowerCurve <- function(x = NULL, 
                           xcutin = 4, xpeak = 14, xpeak2 = 20, xcutoff = 28, 
                           ycutoff = .9, round = 3) { 
  # x - wind speed in m/s
  # xcutin, xcutoff - operational speed of wind (m/s, min and max respectively)
  # xpeak, xpeak2 - the range of speed of with peak (nameplate) power
  # ycutoff - output factor at cut off (max) wind speed
  ff1 <- function(x1) {
    xx <- c(xcutin, 0.5 * (xpeak + xcutin), xpeak)
    xx2 <- xx * xx
    xx3 <- xx * xx2
    yy <- c(0, .3, 1)
    ff <- lm(yy ~ 0 + xx + xx + xx2 + xx3)
    predict(ff, data.frame(
      xx = x1,
      xx2 = x1 * x1,
      xx3 = x1 * x1 * x1
    ))
  }
  ff2 <- function(x2) {
    xx <- c(xpeak2, 0.5 * (xcutoff + xpeak2), xcutoff)
    xx2 <- xx * xx
    xx3 <- xx * xx2
    yy <- c(1, .51 * (ycutoff + 1), ycutoff)
    ff <- lm(yy ~ 0 + xx + xx + xx2 + xx3)
    predict(ff, data.frame(
      xx = x2,
      xx2 = x2 * x2,
      xx3 = x2 * x2 * x2
    ))
  }
  y <- rep(0., length(x))
  ii <- x <= xcutin
  y[ii] <- 0
  ii <- x > xcutoff
  y[ii] <- 0
  ii <- x >= xpeak & x <= xpeak2
  y[ii] <- 1
  ii <- x > xcutin & x < xpeak
  y[ii] <- ff1(x[ii])
  ii <- x > xpeak2 & x <= xcutoff
  y[ii] <- ff2(x[ii])
  return(round(y, round))
  # splinefun(xx, yy, method = "natural")
}

# Check
WindPowerCurve(0:30)
x <- seq(0, 35, by = .1)
plot(x, WindPowerCurve(x), type = "l", col = "blue", lwd = 1, 
     xlab = "Wind speed, m/s", ylab = "Capacity factor")
x1 <- seq(4, 28, by = .1)
points(x1, WindPowerCurve(x1), type = "l", col = "red", lwd = 5)

# Availability factor for wind-energy technologies,
# estimated based on the wind-power curve
gwnd$af50m <- WindPowerCurve(gwnd$WS50M)

# Annual availability factor of wind turbines by location
ywnd <- group_by(gwnd, loc_id, lat, lon, region) %>%
  summarise(af50m = sum(af50m)/365/24)

ggywnd <- function(ii = rep(T, length(ywnd$loc_id))) {
  ggplot(usa49r, aes(long,lat, group = group)) + 
    geom_polygon(colour = "black", fill = "wheat", alpha = .5) +
    coord_fixed(1.45) +
    theme_void() +
    geom_raster(data = ywnd[ii,], aes(lon, lat, fill = af50m), 
                interpolate = F, inherit.aes = F, alpha = .95) +
    scale_fill_distiller(palette = "Blues", direction = 1)
}
ggywnd()
# filtered
ii <- ywnd$af50m >= .15; summary(ii)
ggywnd(ii)

# Aggregation by months
mwnd <- group_by(gwnd, loc_id, lat, lon, region, month) %>%
  summarise(af50m = sum(af50m/mdays)/24)

ggmwnd <- function(mm = rep(T, length(mwnd$loc_id))) {
  ggplot(usa49r, aes(long,lat, group = group)) + 
    geom_polygon(colour = "black", fill = "wheat", alpha = .5) +
    coord_fixed(1.45) +
    theme_void() +
    geom_raster(data = mwnd[mm,], aes(lon, lat, fill = af50m), 
                interpolate = F, inherit.aes = F, alpha = .95) +
    scale_fill_distiller(palette = "Blues", direction = 1) + # , trans = "log10"
    facet_wrap(.~month)
}
ggmwnd()
mm <- mwnd$af50m >= .1; summary(mm)
ggmwnd(mm)

# Averaging by annual potential
# `loc_id_??` is locations with the ranged potential
yy_20 <- ywnd$af50m >= .20; summary(yy_20); loc_id_20 <- ywnd$loc_id[yy_20]
yy_15 <- ywnd$af50m >= .15 & ywnd$af50m < .20; summary(yy_15); loc_id_15 <- ywnd$loc_id[yy_15]
yy_10 <- ywnd$af50m >= .10 & ywnd$af50m < .15; summary(yy_10); loc_id_10 <- ywnd$loc_id[yy_10]

# Check for overlay
any(loc_id_20 %in% loc_id_15) | any(loc_id_10 %in% loc_id_20)

# Assuming 4 megawatts per square kilometer (about 10 megawatts per square mile, NREL)
# for offshore: 3-5 megawatts (MW) per square kilometer
# Taking one grid cell is about ~50x60 km, or ~3000 sq.km, 
# one grid cell can accomodate up to 12GW (3000 * 4 / 1e3) onshore or 9GW offshore. 
# For simplicity let's assume up to 5GW can be used for both
# on- and off-shore wind power capacity per one cell of the grid.
# hist(gwnd$af50m)
gwnd$max_GWh <- 5 * gwnd$af50m # X GW for hourly data

# Onshore wind resource
# Filter and aggregate by regions locations 
# with potential >20% availability factor of wind
ii <- gwnd$loc_id %in% loc_id_20 & gwnd$US_10km_buffer
summary(ii)
wnd_af20 <- group_by(gwnd[ii,], datetime, region) %>%
  summarise(max_GWh = sum(max_GWh, na.rm = T),
            af50m = mean(af50m))
wnd_af20
sum(wnd_af20$max_GWh)/1e3 # Total estimated onshore potential
unique(wnd_af20$region) # regions with onshore wind potential

# Offshore wind resource
ii <- gwnd$loc_id %in% loc_id_20 & gwnd$offshore
summary(ii)
wndf_af20 <- group_by(gwnd[ii,], datetime, region) %>%
  summarise(max_GWh = sum(max_GWh, na.rm = T),
            af50m = mean(af50m))
wndf_af20
sum(wndf_af20$max_GWh)/1e3 # Total offshore wind potential
unique(wndf_af20$region) # regions with offshore wind potential

```

## Weather classes in the model  

Weather classes (in the energyRt package) are used to store/add weather factors to the model data.  

```{r Weather}
# Solar AF
# dim(dhsol)
# head(dhsol)
ii <- rep(T, dim(dhsol)[1]) # filter if needed

SOLAR_AF <- newWeather("SOLAR_AF",
                        description = "Ground level insolation AF",
                        # unit = "kWh/kWh_max",
                        slice = "HOUR",
                        weather = data.frame(
                          region = as.character(dhsol$region[ii]),
                          # year = 2017,
                          slice = dhsol$slice[ii],
                          wval = dhsol$WF[ii]
                        ))

head(SOLAR_AF@weather)
dim(SOLAR_AF@weather)[1] / 49 / 365 / 24 # Check: must be == 1

# Wind AF (onshore)
wnd_af20$slice <- datetime2tsdh(wnd_af20$datetime)
wnd_af20
dim(wnd_af20)[1] / 365/24 # number of regions with the onshore potential
ii <- rep(T, dim(wnd_af20)[1]) # 
summary(wnd_af20$af50m)
# wnd_af20$region <- as.character(wnd_af20$region)
WINON20_AF <- newWeather("WINON20_AF",
                        description = "Onshore wind potential af20",
                        region = unique(wnd_af20$region[ii]),
                        # unit = "kWh/kWh_max",
                        slice = "HOUR",
                        weather = data.frame(
                          region = as.character(wnd_af20$region[ii]),
                          # year = 2010,
                          slice = wnd_af20$slice[ii],
                          wval = wnd_af20$af50m[ii]
                        ))
head(WINON20_AF@weather)
dim(WINON20_AF@weather)[1] / 365 / 24 # Check - number of regions with the data

# Wind AF (offshore)
wndf_af20$slice <- datetime2tsdh(wndf_af20$datetime)
wndf_af20
dim(wndf_af20)[1] / 365/24
ii <- rep(T, dim(wndf_af20)[1]) # 
summary(wndf_af20$af50m)
wndf_af20$region <- as.character(wndf_af20$region)
WINOF20_AF <- newWeather("WINOF20_AF",
                        description = "Offshore wind potential af20",
                        # unit = "kWh/kWh_max",
                        region = unique(wndf_af20$region),
                        slice = "HOUR",
                        weather = data.frame(
                          region = as.character(wndf_af20$region[ii]),
                          # year = 2010,
                          slice = wndf_af20$slice[ii],
                          wval = wndf_af20$af50m[ii]
                        ))
head(WINOF20_AF@weather)
dim(WINOF20_AF@weather)[1] / 365 / 24

```


# Supply
Declaration of resources (upstream technologies) in the model.  
Here we use only solar and wind energy.  

```{r Solar_energy_potential}

RES_SOL <- newSupply(
  name = "RES_SOL",
  description = "Terrestrial solar radiation - maximum potential",
  commodity = "SOL",
  unit = "GWh",
# Weather factors could be used to regulate hourly supply of the resources.
# Though to reduce the model dimension, it is enough to use
# weather factors in technologies.
  # weather = data.frame(
  #   weather = c("SOLAR_AF"),
  #   wava.up =  c(1)
  #   ),
  availability = list(
    # region = dh$region,
    # slice = dh$slice365,
    ava.up = 1e10 # Max available resource in hour, i.e. no limit by now
  ),
  slice = "HOUR"
)

RES_WIN <- newSupply(
  name = "RES_WIN",
  description = "Onshore wind - maximum potential",
  commodity = "WIN",
  region = unique(wnd_af20$region),
  unit = "GWh",
  # weather = data.frame(
  #   weather = c("SOLAR_AF"),
  #   wava.up =  c(1)
  #   ),
  availability = list(
    region = wnd_af20$region,
    slice = wnd_af20$slice,
# here is an alternative (equivalent) way to use weather factors in supply
    ava.up = wnd_af20$max_GWh # Max available resource in hour
  ),
  slice = "HOUR"
)

RES_WFF <- newSupply(
  name = "RES_WFF",
  description = "Offshore wind - maximum potential",
  commodity = "WFF",
  region = unique(wndf_af20$region),
  unit = "GWh",
  # weather = data.frame(
  #   weather = c("SOLAR_AF"),
  #   wava.up =  c(1)
  #   ),
  availability = list(
    region = wndf_af20$region,
    slice = wndf_af20$slice,
    ava.up = wndf_af20$max_GWh # Max available resource in hour
  ),
  slice = "HOUR"
)

```

# Power generating technologies

```{r Technologies}

ESOL <- newTechnology(
  name = "ESOL",
  description = "Utility Scale Solar PV",
  # region = "AZ",
  input = list(
    comm = "SOL",
    unit = "GWh"
  ),
  output = list(
    comm = "ELC",
    unit = "GWh"
  ),
  cap2act = 365*24,
  af = list(
    af.fx = 1 # forcing output when resource is available
  ),
  weather = list(
    weather = c("SOLAR_AF"),
    waf.fx = 1 # weather factor (multiplier) will be applied to af.fx
  ),
  fixom = list(
    fixom = 10 # assumed, 1% of investment costs a year
  ),
  invcost = list(
    # Assuming 1$/Watt 
    # https://www.nrel.gov/news/press/2017/nrel-report-utility-scale-solar-pv-system-cost-fell-last-year.html
    invcost = 1000 # convert("USD/W", "MUSD/GW", 1)
  ),
  start = list(
    start = 2017
  ),
  olife = list(
    olife = 25
  )
)
draw(ESOL)

EWIN <- newTechnology(
  name = "EWIN",
  description = "Onshore wind farm",
   WINON20_AF@region, # Limiting to regions with available resource
  input = list(
    comm = "WIN",
    unit = "GWh"
  ),
  output = list(
    comm = "ELC",
    unit = "GWh"
  ),
  cap2act = 365*24,
  af = list(
    af.fx = 1 # forcing output when resource is available
  ),
  weather = list(
    weather = c("WINON20_AF"),
    waf.fx = c(1)
    # waf.up = c(1) # 
  ),
  fixom = list(
    fixom = 15 # Assumed, 1% a year
  ),
  invcost = list(
    # Assuming 1.5$/Watt 
    # https://www.irena.org/-/media/Files/IRENA/Agency/Publication/2018/Jan/IRENA_2017_Power_Costs_2018.pdf
    invcost = 1500 # 
  ),
  start = list(
    start = 2017
  ),
  olife = list(
    olife = 25
  )
)
draw(EWIN)

EWFF <- newTechnology(
  name = "EWFF",
  description = "Offshore wind farm",
  region = WINOF20_AF@region, # Limiting to regions with available resource
  input = list(
    comm = "WFF",
    unit = "GWh"
  ),
  output = list(
    comm = "ELC",
    unit = "GWh"
  ),
  cap2act = 365*24,
  af = list(
    af.fx = 1 # forcing output when resource is available
  ),
  weather = list(
    weather = c("WINOF20_AF"),
    waf.up = c(1) # 
  ),
  fixom = list(
    fixom = 45 # Assumed, 1% a year
  ),
  invcost = list(
    # Assuming 3-4.5$/Watt 
    # https://www.irena.org/-/media/Files/IRENA/Agency/Publication/2018/Jan/IRENA_2017_Power_Costs_2018.pdf
    # https://www.energy.gov/sites/prod/files/2019/08/f65/2018%20Offshore%20Wind%20Market%20Report.pdf
    invcost = 3500 # convert("USD/W", "MUSD/GW", 1)
  ),
  start = list(
    start = 2017
  ),
  olife = list(
    olife = 25
  )
)
draw(EWFF)

```

# Storage technologies

```{r Storage}
# STGBTR Hourly ####
STGBTR <- newStorage(
  name = 'STGBTR',
  commodity = 'ELC',
  description = "Generic grid-integrated intraday storage (battery)",
  cap2stg = 1, # 
  olife = list(olife = 20), 
  invcost = list(
    # See IRENA 2030 (from 77 to 574, p.77)
    invcost = convert("USD/kWh", "MUSD/GWh", 200)
    ), 
  seff = data.frame(
    inpeff = 0.8, # assumed efficiency of charging 
    stgeff = 0.9 # assumed efficiency of storing energy (annual)
    # outeff = 1 # discharge efficiency
    )
)

STGBTR1 <- newStorage(
  name = 'STGBTR',
  commodity = 'ELC',
  description = "Generic grid-integrated intraday storage (battery)",
  cap2stg = 1, # 
  olife = list(olife = 20), 
  invcost = list(
    # See IRENA 2030 (from 77 to 574, p.77)
    invcost = convert("USD/kWh", "MUSD/GWh", 200)
    ), 
  seff = data.frame(
    inpeff = 0.8, # assumed efficiency of charging 
    stgeff = 0.9, # assumed efficiency of storing energy (annual)
    cinp.up = 24*365 * 2, # 1/2-hour charging
    cout.up = 24*365 / 2 # 2-hour storage (discharging, i.e. GW capacity)
    # outeff = 1 # discharge efficiency
    )
)


# STGP2P Daily - within 365 days ####
STGP2P1 <- newStorage(
  name = 'STGP2P',
  commodity = 'ELC',
  description = "Power-to-power type of technology",
  cap2stg = 1, # if in PJ, convert("GWh", "PJ"),
  olife = list(
    olife = 25), 
  invcost = 50, # USD/kWh, assumption
  seff = data.frame(
    inpeff = 0.8, # power to H2 efficiency
    cinp.up = 24*365 / 100, # speed of P2X conversion for 1GW of storage
    cout.up = 24*365 / 100,  # speed of X2P conversion for 1GW of storage
    outeff = 0.6 # H2 to power efficiency
    # stgeff = .9 
    ),  
  varom = list(
    # Assuming high operational costs, adding ~ 5 cents/kWh
    inpcost = convert("USD/kWh", "MUSD/GWh", .05)
    )
)

```

# Interregional UHV electrical grid

```{r grid_UHV_inv, eval=TRUE}
# Propose trade matrix between regions
{
if (F) { 
  # Load trade matrix from your file
  trd_xl <- readxl::read_excel("data/trade_matrix01.xlsx",
                               range = "A1:AX50")

  trd_nbr <- as.matrix(trd_xl[,-1])
  trd_nbr[lower.tri(trd_nbr)] <- NA
  rownames(trd_nbr) <- trd_xl$region
} else { 
  # Or create trade matrix for all neighbour regions
  trd_nbr <- matrix(rep(NA, nreg_in_gis*nreg_in_gis), 
                    nrow = nreg_in_gis, 
                    dimnames = list(reg_names_in_gis, reg_names_in_gis))
  head(trd_nbr)
  
  for (i in 1:length(reg_names)) {
    trd_nbr[i, nbr[[i]]] <- 1
    trd_nbr[nbr[[i]], i] <- 1
  }
  dim(trd_nbr)
  summary(!is.na(c(trd_nbr)))
  ii <- reg_names_in_gis %in% reg_names
  trd_nbr <- trd_nbr[ii, ii]
  dim(trd_nbr)
  # For bidirectional trade, keep only one direction
  trd_nbr[lower.tri(trd_nbr)] <- NA
  summary(!is.na(c(trd_nbr)))
}
head(trd_nbr)
# write.csv(trd_nbr, file = "data/trade_matrix.csv")
trd_nbr[trd_nbr == 0] <- NA

# Convert the matrix to data.frame (table) format
trd_dt <- as.data.frame.table(trd_nbr, stringsAsFactors = F)
trd_dt <- trd_dt[!is.na(trd_dt$Freq),]
head(trd_dt)
dim(trd_dt)
trd_dt <- dplyr::distinct(trd_dt)
dim(trd_dt)
names(trd_dt) <- c("src", "dst", "trade")
trd_dt$trade <- with(trd_dt, paste0("TRBD_UHV_", src, "_", dst))
head(trd_dt)

# Map region flows
trd_map <- left_join(trd_dt, reg_centers[,1:3], by = c("src" = "region"))
trd_map <- left_join(trd_map, reg_centers[,1:3], by = c("dst" = "region"))
trd_map <- trd_map %>% 
  rename(xsrc = x.x, ysrc = y.x,
         xdst = x.y, ydst = y.y)
trd_map <- as_tibble(trd_map)

# Filter excessive connections
dim(trd_dt); dim(trd_map)
drop_route <- function(reg1, reg2) {
  (trd_dt$src == reg1 & trd_dt$dst == reg2) | (trd_dt$src == reg2 & trd_dt$dst == reg1)
}
# trd_dt[ii & grepl("TJ", trd_dt$trade),]
ii <- rep(TRUE, length(trd_dt$src))
ii <- ii & !drop_route("AL", "FL")
ii <- ii & !drop_route("GA", "NC")
ii <- ii & !drop_route("CT", "RI")
ii <- ii & !drop_route("VT", "MA")
ii <- ii & !drop_route("NY", "MA")
ii <- ii & !drop_route("PA", "DE")
ii <- ii & !drop_route("UT", "NM")
ii <- ii & !drop_route("VA", "DC")
ii <- ii & !drop_route("AL", "TN")
length(trd_dt$src[ii])

library(ggrepel)
trd_flows_map <-
ggplot(data = usa49r) + 
  geom_polygon(aes(x = long, y = lat, group = group), fill = "wheat", 
               colour = "white", alpha = 1, size = .5) + # aes fill = id, 
  coord_fixed(1.3) +
  guides(fill=FALSE) +  # do this to leave off the color legend
  theme_void() + labs(title = "Open interregional electricity trade routes (long distance grid)")  + 
  theme(plot.title = element_text(hjust = 0.5), 
        plot.subtitle = element_text(hjust = 0.5)) +
  geom_segment(aes(x=xsrc, y=ysrc, xend=xdst, yend=ydst), 
               data = trd_map[ii,], inherit.aes = FALSE, size = 3, 
               alpha = 1, colour = "grey", lineend = "round", show.legend = T) +
  geom_point(data = reg_centers, aes(x, y), colour = "white") +
  geom_segment(aes(x=xsrc, y=ysrc, xend=xdst, yend=ydst), 
               data = trd_map[ii,], inherit.aes = FALSE, size = .1, 
           # arrow = arrow(type = "closed", angle = 15, 
           #               length = unit(0.15, "inches")),
           colour = "white", alpha = 1, 
           lineend = "butt", linejoin = "mitre", show.legend = T) + # , name = "Trade, PJ"
  geom_text_repel(aes(x, y, label = region), data = reg_centers)
trd_flows_map
trd_map <- trd_map[ii,]; rownames(trd_map) <- NULL
trd_dt <- trd_dt[ii,]; rownames(trd_dt) <- NULL
# ggsave("fig/trd_flows_map.pdf", trd_flows_map, device = "pdf")
}
# Calculate distance between regions centers:
labpt <- getCenters(usa49reg)
# rownames(labpt) <- labpt[,"region"]

# Estimate grid length, losses, costs
trd_dt$distance_km <- 0.
for (i in 1:dim(trd_dt)[1]) {
  rg_dst <- trd_dt$dst[i]
  rg_src <- trd_dt$src[i]
  ii <- labpt$region == rg_dst
  lab_dst <- c(labpt$x[ii], labpt$y[ii])
  ii <- labpt$region == rg_src
  lab_src <- c(labpt$x[ii], labpt$y[ii])
  trd_dt$distance_km[i] <- raster::pointDistance(
    lab_src, lab_dst, T)/1e3
}

# Assume 15% longer distance due to a landscape
trd_dt$distance_km <- 1.15 * trd_dt$distance_km
# Assume losses 2% per 1000 km
# trd_dt$losses <- round(trd_dt$distance_km / 1e3 * 0.02, 4)
# Assume losses 1% per 1000 km (UHVDC)
trd_dt$losses <- round(trd_dt$distance_km / 1e3 * 0.01, 4)
trd_dt$teff <- 1 - trd_dt$losses
# Assumption based on ABB's 4000-8000 MUSD per 12GW UHVDC, 2000km, 1-5% system losses
# i.e. ~$160-333 MUSD/1000km per 1GW of the total system 
# assuming ~$200 MUSD/1000km per 1GW of power line,
# and $50 MUSD/GW for converter stations on each end
trd_dt$invcost <- round(trd_dt$distance_km / 1e3 * 200) # MUSD/GW of 1000km UHVDC
trd_dt <- as_tibble(trd_dt)

# Define trade object for every route, 
# store in a repository object
TRBD_UHV_NEI <- newRepository(name = "TRBD_UHV_NEI")
for (i in 1:dim(trd_dt)[1]) {
  src <- trd_dt$src[i]
  dst <- trd_dt$dst[i]
  trd_nm <- paste0("TRBD_UHV_", src, "_", dst)  # Trade object name
  cmd_nm <- "UHV"
  # Trade class for every route
  trd <- newTrade(trd_nm,
                  commodity = cmd_nm,
                  # source = c(src, dst),
                  # destination = c(src, dst),
                  routes = list(
                    src = c(src, dst),
                    dst = c(dst, src)
                  ),
                  trade = data.frame(
                    src = c(src, dst),
                    dst = c(dst, src),
                    # Maximum capacity per route in GW
                    # ava.up = convert("GWh", "GWh", 60), (!!! bug)
                    teff = trd_dt$teff[i] # trade losses
                    # cost = trd_dt$cost[i]  # trade costs
                    # markup = trd_dt$cost[i] # and/or markup
                    ),
                  #!!! New stuff - testing
                  capacityVariable = TRUE, # The trade route has capacity (not just flow) and can be endogenous
                  # bidirectional = TRUE, #
                  invcost = data.frame(
                    # src = src,
                    # dst = dst,
                    # year = 2010,
                    region = c(dst, src),
                    invcost = trd_dt$distance_km[i] / 1e3 * 250 / 2 # 
                  ),
                  # olife = data.frame(
                  olife = 80,
                  # ),
                  cap2act = convert("GWh", "GWh", 24*365)
                  )
  
  TRBD_UHV_NEI <- add(TRBD_UHV_NEI, trd)
}
names(TRBD_UHV_NEI@data)
TRBD_UHV_NEI@data[[1]]

```

# Inverter and rectifier stations
```{r UHV_rectifiers_inverters}
# Parameters assumed or calibrated based on 
# ABB's 4000-8000 MUSD per 12GW, 2000km, 1-5%
# and other sources

ELC2UHV <- newTechnology(
  name = "ELC2UHV",
  description = "Converter stations - ELC to UHV",
  input = list(
    comm = "ELC",
    unit = "GWh"
    # unit = "PJ"
  ),
  output = list(
    comm = "UHV",
    unit = "GWh"
    # unit = "PJ"
  ),
  # cap2act = 31.536,
  cap2act = 24*365,
  ceff = list(
    comm = "ELC",
    cinp2use = .99 # see also Siemens -- 3% total losses for HVDC/1000km
  ),
  slice = "HOUR",
  invcost = list(
    invcost = 50  # 
  ),
  olife = 20 # assumed
)  
draw(ELC2UHV)


UHV2ELC <- newTechnology(
  name = "UHV2ELC",
  description = "Converter stations - UHV to ELC",
  input = list(
    comm = "UHV",
    unit = "GWh"
    # unit = "PJ"
  ),
  output = list(
    comm = "ELC",
    unit = "GWh"
    # unit = "PJ"
  ),
  # cap2act = 31.536,
  cap2act = 24*365,
  ceff = list(
    comm = "UHV",
    cinp2use = .99
  ),
  slice = "HOUR",
  invcost = list(
    invcost = 50 # Assumed, based on ABB data
  ),
  olife = 20 # assumed
)  
draw(UHV2ELC)

```

# Trade with the rest of the world (ROW)  
Currently used to estimate curtailments and the system failure to meet the demand.  

```{r ROW_trade}

EEXP <- newExport(
  name = "EEXP",
  description = "Supply curtalments (artificial export to capture excessive ELC production by renewables)",
  commodity = "ELC",
  exp = list(
    price = convert("USD/kWh", "MUSD/GWh", .01/1000) # 1/1000 cents per kWh
  )
)

EIMP <- newImport(
  name = "EIMP",
  description = "Demand curtailments, electricity import at high price (to identify shortages)",
  commodity = "ELC",
  imp = list(
    price = convert("USD/kWh", "MUSD/GWh", 1) # USD per kWh, marginal price
  )
)

```

```{r CPLEX_params}
{cplex_options <- "
*$exit
option iterlim = 1e9;
option reslim = 2e5;
option LP = CPLEX;
option threads=16;
option savepoint=1;
*option bRatio = 0;
*execute_loadpoint 'energyRt_p';
$onecho > cplex.opt
interactive 1
advind 0
*tuningtilim 2400
aggcutlim 3
aggfill 10
aggind 25
bardisplay 2
parallelmode -1
lpmethod 6
*printoptions 1
names no
*freegamsmodel 1
*memoryemphasis 1 
$offecho
*$exit
energyRt.OptFile = 1;
"
} # GAMS & CPLEX parameters ####

{inc_after_solve <- 
"parameter zModelStat;
zModelStat = energyRt.ModelStat; 
execute_unload 'USENSYS_scenario.gdx';"}
  
if (F) { # Save the workspace (mannual)
  save.image(file = "data/USENSYS_RENBAL_v02.RData")
  load("data/USENSYS_RENBAL_v02.RData")
}

```

# The Model  
The base model and scenario:  
- generic electricity (ELC);  
- three types of renewables; 
- two types of energy storage;  
- no inter-regional trade/dispatch.  

```{r Model_RENBAL, eval=TRUE}
# Repository with all the data-objects
reps <- add(newRepository('main_repository'), 
  # Commodities
  ELC, SOL, WIN, WFF, #UHV,
  # Resources (supply)
  RES_SOL, RES_WIN, RES_WFF,
  # Weather factors
  SOLAR_AF, WINOF20_AF, WINON20_AF,
  # Generating technologies
  ESOL, EWIN, EWFF,
  # Storage
  STGBTR1, #STGP2P1,
  # Simplified interregional ELC trade
  # TRD_ELC_ALL,
  # UHV grid
  # TRBD_UHV_NEI,
  # ELC2UHV, UHV2ELC,
  # Export/Import,
  EEXP, EIMP,
  # ELC demand with load curve (24 hours x 365 days)
  DEM_ELC_DH # static
)
length(reps@data)
names(reps@data)

# model-class object 
mdl <- newModel(
  name = 'RENBAL', 
  description = "Renewables balancing model",
  ## in case of infeasibility, `dummy` variables can be added
  # debug = data.frame(#comm = "ELC",
  #                    dummyImport = 1e6,
  #                    dummyExport = 1e6),
  region = reg_names,
  discount = 0.05,
  slice = list(ANNUAL = "ANNUAL",
               # MONTH = timeslices$MONTH, 
               # HOUR = timeslices$HOUR
               YDAY = timeslices365$YDAY, 
               HOUR = timeslices365$HOUR
               ),
  repository = reps,
  GIS = usa49reg,
  early.retirement = F)

# Check the model time-slices
head(mdl@sysInfo@slice@levels)

# Set milestone-years
# mdl <- setMilestoneYears(mdl, start = 2015, interval = c(1, 2, 5, 6, 7, rep(10, 3)))
mdl <- setMilestoneYears(mdl, start = 2017, interval = c(1))
mdl@sysInfo@milestone # check

# (optional) the model info
{mdl@description <- "
USENSYS, power sector, renewables balancing version,
49 regions, 1 hour resolution,
3 types of renewables, 
1 types of storages,
no initial stock."}

# (optional) GAMS and CPLEX options
mdl@misc$includeBeforeSolve <- cplex_options
# (optional) save GDX file with the solution
mdl@misc$includeAfterSolve <- inc_after_solve

```

# Scenario 0
```{r scen_REN0, eval=FALSE}
# Workflow to solve the model (recommended for large models):
# 1. Interpolation of parameters
scen_REN0 <- interpolate(mdl, name = "RENBAL0", 
  description = "No inter-regional dispatch.")
size(scen_REN0)

# 2. Writing the model code and data in folder
write_model(scen_REN0, tmp.dir = "solwork/RENBAL0", solver = "GAMS")
# save(scen_REN0, file = "solwork/scen_REN0.RData")

# 3. Solving the model
solve_model(tmp.dir = "solwork/RENBAL0", wait = FALSE)
# Alterntively, run GAMS directly in the model folder: 'gams mdl'

# 4. Read the solution
# load(scen_REN0, file = "solwork/scen_REN0.RData")
scen_REN0 <- read_solution(scen_REN0, dir.result = "solwork/RENBAL0")
summary(scen_REN0)

save(scen_REN0, file = "scenarios/scen_RENBAL0.RData")
# load("scenarios/scen_RENBAL0.RData")

```

# Scenario 4
```{r scen_REN4, eval=FALSE}
# (optional) Scenario info:
{scen_descr <- "
USENSYS, power sector, balancing version,
49 regions, 1 hour resolution,
3 types of renewables, 
1 type of storage,
no initial stock,
endogenous UHV grid (neighbours matrix), no limit,
converter stations."}

# 1. Interpolation of parameters
scen_REN4 <- interpolate(
  add(mdl, UHV, TRBD_UHV_NEI, ELC2UHV, UHV2ELC), 
  name = "RENBAL4")
save(scen_REN4, file = "tmp/scen_REN4_interpolated.RData")

# 2. Writing the model code and data in folder
write_model(scen_REN4, tmp.dir = "solwork/RENBAL4", solver = "GAMS")

# 3. Solving the model
solve_model(tmp.dir = "solwork/RENBAL4", wait = FALSE)
# Alterntively, run GAMS directly in the model folder: 'gams mdl'

# 4. Read the solution
# load("tmp/scen_REN4_interpolated.RData")
# scen_REN4 <- read_solution(scen_REN4, dir.result = "solwork/RENBAL4ZZ")
scen_REN4 <- read_solution(scen_REN4, dir.result = "solwork/RENBAL4")
summary(scen_REN4)

save(scen_REN4, file = "scenarios/scen_RENBAL4.RData")
# load("scenarios/scen_RENBAL4.RData")

# scen_REN5 <- read_solution(scen_REN4, dir.result = "solwork/RENBAL5")
# scen_REN5@name <- "RENBAL5"
# summary(scen_REN5)
# save(scen_REN5, file = "scenarios/scen_RENBAL5.RData")
# 

```

# Scenario 7: limit on grid 25% inv
```{r scen_REN7, eval=FALSE}
# Unrestricted (optimal) grid capacity from M3S4
msy <- mdl@sysInfo@milestone$mid

(vTradeCap <- getData(scen_REN4, name = "vTradeCap", merge = T, year = max(msy),
                      newNames = c(value = "GW")))
summary(vTradeCap$GW)

trd_TWkm <- full_join(trd_dt, select(vTradeCap, trade, GW)) %>%
  mutate(TWkm = distance_km / 1e3 * GW)
sum(trd_TWkm$TWkm, na.rm = T) # TW*km

# Unrestricted (optimal) grid investment in M3S4
(vTradeInv <- getData(scen_REN4, name = "vTradeInv", merge = T))
sum(vTradeInv$value) / 1e3 # Billion USD
sum(vTradeInv$value)/sum(trd_TWkm$TWkm, na.rm = T) # Check invcost

GRIDINV50 <- newConstraint(
  'GRIDINV50', eq = '<=', rhs = sum(vTradeInv$value)/2,
  variable = list(variable = 'vTradeInv'))

GRIDINV25 <- newConstraint(
  'GRIDINV25', eq = '<=', rhs = sum(vTradeInv$value)/4,
  variable = list(variable = 'vTradeInv'))

# mdl2 <- mdl
# mdl2@data$main_repository@data$EIMP <- EIMPLO

# 1. Interpolation of parameters
scen_REN7 <- interpolate(
  add(mdl, UHV, TRBD_UHV_NEI, ELC2UHV, UHV2ELC, GRIDINV25), 
  name = "scen_REN7")
# save(scen_REN7, file = "tmp/scen_REN7_interpolated.RData")

# 2. Writing the model code and data in folder
write_model(scen_REN7, tmp.dir = "solwork/scen_REN7", solver = "GAMS")

# 3. Solving the model
solve_model(tmp.dir = "solwork/scen_REN7", wait = FALSE)

# 4. Read the solution
# load("tmp/scen_REN7_interpolated.RData")
scen_REN7 <- read_solution(scen_REN7, dir.result = "solwork/scen_REN7")
summary(scen_REN7)

save(scen_REN7, file = "scenarios/scen_REN7.RData")
load("scenarios/scen_REN7.RData")

```


# Check the results  
```{r quick_check}
if (!exists("scen")) {
  if(!exists("scen_REN")) load("scenarios/scen_RENBAL.RData")
  ls(pattern = "scen_")
  # Chose one of the scenarios
  scen <- scen_REN0
  scen <- scen_REN4
  scen <- scen_REN7

}
scen@name

# Objective (system costs)
(vObjective <- getData(scen, name = "vObjective", merge = T))

# Total electricity output from generating technologies
(vTechOut_ELC <- getData(scen, name = "vTechOut", comm = "ELC", tech_ = "^E", 
                         merge = T))
unique(vTechOut_ELC$tech)

# Total demand
(pDemand_ELC <- getData(scen, name = "pDemand", comm = "ELC", merge = T))
sum(pDemand_ELC$value)

# Total ELC Output vs Demand
sum(vTechOut_ELC$value) / sum(pDemand_ELC$value)

# System costs USD/kWh (== MUSD/GWh)
## for electricity consumed
vObjective$value / sum(pDemand_ELC$value)
## for electricity produced
vObjective$value / sum(vTechOut_ELC$value)

# Supply curtailments
(vExportROW_ELC <- getData(scen, name = "vExportRow", merge = T)) 
sum(vExportROW_ELC$value)/sum(pDemand_ELC$value)

# Demand curtailments
(vImportROW_ELC <- getData(scen, name = "vImportRow", merge = T)) 
sum(vImportROW_ELC$value)/sum(pDemand_ELC$value)

# Generating capacity 
(vTechCap <- getData(scen, name = "vTechCap", merge = T))
vTechCap %>%
  group_by(scenario, tech, year) %>%
  summarise(GW = sum(value))

# Storage capacity
getData(scen, name = "vStorageCap", merge = T)
sum(getData(scen, name = "vStorageCap", merge = T)$value)
getData(scen, name = "vStorageCap", merge = T) %>%
  group_by(scenario, stg, region, year) %>%
  summarize(GW = sum(value))
(vStorageCap_STGP2X <- getData(scen, name = "vStorageCap", merge = T, stg = "STGP2P"))
(vStorageCap_STGBTR <- getData(scen, name = "vStorageCap", merge = T, stg = "STGBTR"))
sum(vStorageCap_STGP2X$value) # GWh - interdday (~seasonal) storage
sum(vStorageCap_STGBTR$value) # GWh - intraday (hourly) storage
sum(vStorageCap_STGP2X$value)/sum(pDemand_ELC$value) * 100

# Ir-Trade


```

# Shape of supply
```{r}
(vTechOut_ELC <- getData(scen, name = "vTechOut", comm = "ELC", 
                         tech_ = "^E",
                         merge = T, newNames = c("value" = "GWh")))
summary(vTechOut_ELC$GWh)
unique(vTechOut_ELC$tech)

supy <- vTechOut_ELC %>%
  mutate(hour = as.integer(substr(slice, 7,8))) %>%
  group_by(scenario, year, hour, tech) %>%
  summarize(TWh = sum(GWh)/1e3) %>%
  mutate(tech = factor(tech, 
                       levels = c("ESOL", "EWFF", "EWIN"), 
                       ordered = T))

ggplot(supy) + 
  geom_area(aes(x = hour, y = TWh, fill = tech), stat = "identity") +
  labs(title = "Annual generation profile")


supm <- vTechOut_ELC %>%
  mutate(#hour = as.integer(substr(slice, 7,8)),
         month = month(as.Date ("2017-01-01") + as.integer(substr(slice, 2, 4)) - 1)) %>%
  mutate(month.name = factor(month.name[month], levels = month.name[1:12], ordered = T)) %>%
  group_by(scenario, year, month, month.name, tech) %>%
  summarize(TWh = sum(GWh)/1e3) %>%
  mutate(tech = factor(tech, 
                       levels = c("ESOL", "EWFF", "EWIN"), 
                       ordered = T))
ggplot(supm) + 
  geom_bar(aes(x = month.name, y = TWh, fill = tech), stat = "identity") 

```

# Capacity maps
```{r Capacity_maps}
cap_2017 <- getData(scen, name = "vTechCap", merge = T)

# Technologies capacity
# fig_map_cap_2017_by_tech <-
ggplot(data = usa49r) + 
  geom_polygon(aes(x = long, y = lat, group = group), fill = "grey85", 
                   colour = "white", alpha = 1, size = .5) +
    geom_polygon(aes(x = long, y = lat, group = group, fill = value),
                     data = right_join(usa49r, cap_2017, by = c("id" = "region")), #fill = "wheat", 
                 color = "white", alpha = 1, size = 0.25, inherit.aes = F) + # aes fill = id, 
  coord_fixed(1.3) +
  theme_void() +
  # scale_fill_distiller(palette = "Spectral", direction = -1, name = "GW") +
  scale_fill_distiller(palette = "Spectral", direction = -1, trans = "log10", name = "GW") +
  labs(title = "Installed technologies") +
  theme(plot.title = element_text(hjust = 0.5), 
        plot.subtitle = element_text(hjust = 0.5)) +
  facet_wrap(.~tech, ncol = 2)
    # facet_wrap(.~tech, ncol = 2, scales = "free")
# fig_map_cap_2017_by_tech
# ggsave(file.path("fig", scen@name,"fig_map_cap_2017_by_tech.pdf"), fig_map_cap_2017_by_tech, device = "pdf")

# Storage capacity
stg_2017 <- getData(scen, name = "vStorageCap", merge = T)
# stg_2017$GWh <- convert("PJ", "GWh", stg_2017$value)
stg_2017$GWh <- convert("GWh", "GWh", stg_2017$value)
fig_map_stg_2017 <-
ggplot(data = usa49r) + 
  geom_polygon(aes(x = long, y = lat, group = group), fill = "grey85", 
                   colour = "white", alpha = 1, size = .5) +
    geom_polygon(aes(x = long, y = lat, group = group, fill = GWh),
                     data = right_join(usa49r, stg_2017, by = c("id" = "region")), #fill = "wheat", 
                 color = "white", alpha = 1, size = 0.25, inherit.aes = F) + # aes fill = id, 
    coord_fixed(1.3) +
    # scale_fill_distiller(palette = "Spectral", direction = -1, name = "GW") +
    scale_fill_distiller(palette = "Spectral", direction = -1, trans = "log10") +
    theme_void() + facet_wrap(.~stg)
fig_map_stg_2017

# ggsave(file.path("fig", scen@name,"fig_map_stg_2017.pdf"), fig_map_stg_2050, device = "pdf")


```

# Storage operation
```{r }
getData(scen, name_ = "vStorage")

# (vStorageInp_STGP2P <- getData(scen, name = "vStorageInp", merge = T, stg = "STGP2P"))
# max(vStorageInp_STGP2P$value)

(vSTGBTR <- getData(scen, 
          name = c("vStorageInp", "vStorageOut", "vStorageStore"),
          merge = T, stg = "STGBTR", slice_ = "d10[1-2]", region = "CA"))

ggplot(vSTGBTR) + 
  geom_bar(aes(x = slice, y = value, fill = name), stat = "identity") +
  theme(axis.text.x = element_text(angle = 90))

tSTGBTR <- vSTGBTR %>%
  spread(key = name, value = value)

summary(tSTGBTR$vStorageInp)
summary(tSTGBTR$vStorageOut)
summary(tSTGBTR$vStorageStore)


# (vSTGP2P <- getData(scen, 
#           name = c("vStorageInp", "vStorageOut", "vStorageStore"),
#           merge = T, stg = "STGP2P", slice_ = "d01", region = "ND"))

# vSTGBTR %>%
#   spread()

# ggplot(vSTGP2P) + 
#   geom_bar(aes(x = slice, y = value, fill = name), stat = "identity") +
#   # theme_void() +
#   theme(axis.text.x = element_text(angle = 90))
  

```


# Trade flows maps
```{r Trade flows}
scen@name
trdIr <- getData(scen, name = "vTradeIr", merge = T)
summary(trdIr$value)
# summary(convert("PJ", "GWh", trdIr$value))
trdIr[which(trdIr$value == max(trdIr$value)), ]
tt <- sort(unique(trdIr$trade))
tt

trdIr_year <- trdIr %>%
  group_by(src, dst, year) %>%
  # summarize(TWh = convert("PJ", "TWh", sum(value)))
  summarize(
    GW = max(value),
    GWh = sum(value))
trdIr_year

trd_elc_y <- trdIr_year %>%
  left_join(reg_centers, by = c("src" = "region")) %>%
  rename(xsrc = x, ysrc = y) %>%
  left_join(reg_centers, by = c("dst" = "region")) %>%
  rename(xdst = x, ydst = y) 


# trd_elc_y <- left_join(trdIr_year, trd_map)
summary(trd_elc_y$GWh)/24/365
summary(trd_elc_y$GW)
trd_elc_y[is.na(trd_elc_y$GWh),]

trd_flows_map
ggplot(data = usa49r) + 
    geom_polygon(aes(x = long, y = lat, group = group), fill = "wheat", 
                 colour = "white", alpha = 1, size = .5) + # aes fill = id, 
    coord_fixed(1.3) +
    guides(fill=FALSE) +  # do this to leave off the color legend
    theme_void() + labs(title = "Annual interregional electricity trade flows")  + 
    theme(plot.title = element_text(hjust = 0.5), 
          plot.subtitle = element_text(hjust = 0.5)) +
    geom_segment(aes(x=xsrc, y=ysrc, xend=xdst, yend=ydst, size = GWh/1e3), 
    # geom_segment(aes(x=xsrc, y=ysrc, xend=xdst, yend=ydst, size = GWh/1e3), 
    # geom_segment(aes(x=xsrc, y=ysrc, xend=xdst, yend=ydst, size = GWh/1e2/8760), 
                 data = trd_elc_y, inherit.aes = FALSE, #size = 3, 
                 alpha = 1, colour = "dodgerblue", lineend = "round", show.legend = T) +
    geom_point(data = reg_centers, aes(x, y), colour = "red") +
    geom_segment(aes(x=xsrc, y=ysrc, xend=xdst, yend=ydst), 
                 data = trd_elc_y, inherit.aes = FALSE, size = .1, 
             arrow = arrow(type = "closed", angle = 15, 
                           length = unit(0.15, "inches")),
             colour = "white", alpha = 0.75, 
             lineend = "butt", linejoin = "mitre", show.legend = T)





```

# Grid capacity
```{r Grid_cap}
scen@name
vTradeCap <- getData(scen, name = "vTradeCap", merge = T, newNames = c("value" = "GW"))
summary(vTradeCap$GW)
# summary(convert("PJ", "GWh", trdIr$value))
# vTradeCap[which(vTradeCap$GW == max(vTradeCap$GW)), ]

# getData(scen, name_ = "pTrade", merge = F)
getData(scen, name = "vTradeNewCap")

vTradeCap <- vTradeCap %>%
  full_join(trd_dt) %>%
  left_join(reg_centers, by = c("src" = "region")) %>%
  rename(xsrc = x, ysrc = y) %>%
  left_join(reg_centers, by = c("dst" = "region")) %>%
  rename(xdst = x, ydst = y) 
    

ii <- vTradeCap$GW >= 0 # filter grid capacity if needed

ggplot(data = usa49r) + 
  geom_polygon(aes(x = long, y = lat, group = group), fill = "wheat", 
               colour = "white", alpha = 1, size = .5) + # aes fill = id, 
  coord_fixed(1.3) +
  guides(fill=FALSE) +  # do this to leave off the color legend
  theme_void() + labs(title = "Optimized UHV grid capacity")  + 
  theme(plot.title = element_text(hjust = 0.5), 
        plot.subtitle = element_text(hjust = 0.5)) +
  geom_segment(aes(x=xsrc, y=ysrc, xend=xdst, yend=ydst, size = GW), 
  # geom_segment(aes(x=xsrc, y=ysrc, xend=xdst, yend=ydst, size = GWh/1e3), 
  # geom_segment(aes(x=xsrc, y=ysrc, xend=xdst, yend=ydst, size = GWh/1e2/8760), 
               data = vTradeCap[ii,], inherit.aes = FALSE, #size = 3, 
               alpha = 1, colour = "dodgerblue", lineend = "round", show.legend = T) +
  scale_size_continuous(range = c(1, 5)) +
  geom_segment(aes(x=xsrc, y=ysrc, xend=xdst, yend=ydst), 
               data = vTradeCap[ii,], inherit.aes = FALSE, size = .1, 
           # arrow = arrow(type = "closed", angle = 15, 
           #               length = unit(0.15, "inches")),
           colour = "white", alpha = 0.75, 
           lineend = "butt", linejoin = "mitre", show.legend = T) +
  geom_point(data = reg_centers, aes(x, y), colour = "white")
  

```

# Curtailments  
(ROW export and import)  
```{r Curtailments_maps}
# Supply curtailments
curtail <- getData(scen, name = c("vExportRow", "vImportRow"), merge = T,
                   newValues = list(name = c(
                     "vExportRow" = "Supply",
                     "vImportRow" = "Demand"
                   )))
curtail_y <- curtail %>%
  group_by(scenario, name, region, year) %>%
  summarise(
    Hours = n(),
    GWh = sum(value)) %>%
  mutate(TWh = GWh/1e3)

summary(curtail_y$Hours[grepl("Demand", curtail_y$name)])/24/365 * 100 #%

ggplot(data = usa49r) + 
  geom_polygon(aes(x = long, y = lat, group = group), fill = "grey85", 
                   colour = "white", alpha = 1, size = .5) +
    geom_polygon(aes(x = long, y = lat, group = group, fill = Hours),
                     data = right_join(usa49r, curtail_y, by = c("id" = "region")), #fill = "wheat", 
                 color = "white", alpha = 1, size = 0.25, inherit.aes = F) + # aes fill = id, 
  coord_fixed(1.3) +
  theme_void() +
  # scale_fill_distiller(palette = "Spectral", direction = -1, name = "GW") +
  scale_fill_distiller(palette = "Spectral", direction = -1, trans = "log10", name = "Hours") +
  labs(title = "Curtailments") +
  theme(plot.title = element_text(hjust = 0.5), 
        plot.subtitle = element_text(hjust = 0.5)) +
  facet_wrap(.~name, ncol = 1)




```

# Costs
```{r Costs}
sns <- list("GRID100" = scen_REN4, 
            # "GRID50" = scen_REN8,
            "GRID25" = scen_REN7, 
            "GRID0" = scen_REN0)

vInvAll <- getData(sns, merge = T,
                   name = c("vTechInv", "vStorageInv", "vTradeInv"), 
                   newNames = c("stg" = "process", "tech" = "process", "trade" = "process"),
                   newValues = list(name = c(
                     "vTechInv" = "Generation",
                     "vStorageInv" = "Storage",
                     "vTradeInv" = "Grid"
                     )))
vInvAll

aa <- getData(sns, name = "vTradeInv", merge = T)
sum(aa$value)

inv_all_reg <- vInvAll %>% 
  group_by(scenario, name) %>%
  summarise(MUSD = sum(value)) %>%
  mutate(
    BUSD = MUSD/1e3,
    TUSD = MUSD/1e6)
inv_all_reg
sum(inv_all_reg$TUSD) / 20

inv_all_reg$scenario <- factor(inv_all_reg$scenario, 
                               levels = c("GRID100", 
                                          # "GRID50", 
                                          "GRID25",
                                           "GRID0"),
                               ordered = T)

ggplot(inv_all_reg) +
  geom_bar(aes(x = scenario, y = BUSD, fill = name), stat = "identity") + 
  scale_fill_brewer(palette = "Set1") + 
  labs(y = "Billion USD")



vEacAll <- getData(sns, merge = T,
                   name = c("vTechEac", "vStorageEac", "vTradeEac"), 
                   newNames = c("stg" = "process", "tech" = "process", "trade" = "process"),
                   newValues = list(name = c(
                     "vTechEac" = "Generation",
                     "vStorageEac" = "Storage",
                     "vTradeEac" = "Grid"
                     )))
vEacAll



eac_all_reg <- vEacAll %>% group_by(scenario, process, name) %>%
  summarise(MUSD = sum(value)) %>%
  mutate(
    BUSD = MUSD/1e3,
    TUSD = MUSD/1e6)
eac_all_reg$process[grepl("TRBD_", eac_all_reg$process)] <- "GRID"
eac_all_reg$scenario <- factor(eac_all_reg$scenario, 
                               # levels = , 
                               levels = c("GRID100", 
                                          # "GRID50", 
                                          "GRID25",
                                           "GRID0"),
                               ordered = T)


ggplot(eac_all_reg) +
  geom_bar(aes(x = scenario, y = BUSD, fill = process), stat = "identity") + 
  scale_fill_brewer(palette = "Set1") + 
  labs(y = "Billion USD")


getData(scen, name = "vObjective", merge = T)
vEac <- getData(
  scen, name_ = "Eac|eac", merge = T, parameters = F, 
  newNames = c("stg" = "process", "tech" = "process", "trade" = "process")) %>% 
  group_by( name) %>%
  summarise(MUSD = sum(value))
vEac
sum(vEac$MUSD)



```

